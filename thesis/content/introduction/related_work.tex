\section{Related Work} \label{sec:related_work}

Several surveys have synthesized the state of the art in motion planning for autonomous driving.
Claussmann et al.
compare classical graph-search algorithms, sampling-based methods, and optimization-based planners,
emphasizing the need for trajectories that respect vehicle dynamics and safety constraints, particularly in high-speed highway scenarios \cite{claussmann_review_2020}.
They highlight the role of Model Predictive Control (MPC) in generating feasible and efficient trajectories.

For urban driving, Paden et al.
categorize planning methods into variational, graph-based, and sampling-based approaches, stressing how model fidelity and computational constraints
influence method selection \cite{paden_survey_2016}.
They highlight the effectiveness of convex formulations, such as quadratic programming, in making trajectory optimization tractable while balancing
accuracy and efficiency.

González et al.
provide a broader review, identifying two key challenges: avoiding moving obstacles and ensuring real-time re-planning in dynamic environments \cite{gonzalez_bautista_review_2015}.
They note advancements in computing and optimization that enable real-time trajectory generation but emphasize the trade-off between solution
optimality and computational feasibility.

Across these works, a common theme emerges: motion planning must balance vehicle dynamics, safety constraints, and computational efficiency.
Convex optimization has become a crucial tool in achieving this balance, setting the stage for the methods explored in this thesis.
\subsection{Classical Motion Planning Approaches}

Early motion planning research focused on finding feasible paths in a geometric sense, often treating the vehicle as a point mass and ignoring
detailed dynamics.
Graph-based algorithms (e.g., A*, D* \cite{dolgov_path_2010}) discretize the state or configuration space into grids or lattices to search for
collision-free paths, but they can become computationally intractable in high-dimensional spaces.
Sampling-based planners, such as Probabilistic Roadmaps (PRM) and Rapidly-exploring Random Trees (RRT), offered a breakthrough in efficiency by
randomly sampling the continuous configuration space \cite{orthey_sampling-based_2024}.
PRM methods construct a graph of randomly-sampled collision-free configurations, while RRT incrementally grows a tree from the start state toward the
goal by sampling random inputs \cite{orthey_sampling-based_2024}.
These methods are probabilistically complete, meaning they will find a solution if one exists given enough time.
Variants like RRT* and PRM* were later developed to achieve asymptotic optimality (convergence towards the optimal path as samples increase) for
metrics like path length.

Despite their success in finding feasible paths even in high-dimensional or complex environments, classical planners have notable limitations.
They typically produce geometric paths without timing information, requiring a separate velocity profile or trajectory generation step to account for
kinematics and dynamics.
Moreover, they do not inherently optimize a specific cost function (beyond maybe path length for RRT*), so the resulting paths may be suboptimal in
terms of travel time, energy, or comfort.
In practice, an initial path from a sampling or graph search planner often needs refinement.
For example, trajectory optimization algorithms are commonly employed to smooth and shorten a raw path from an RRT or grid planner
\cite{schulman_finding_2013}, adjusting the path points or timing to satisfy dynamic constraints and improve optimality.
This two-stage approach (planning then post-optimization) can work, but it separates feasibility and optimality into distinct steps.
The transition to optimization-based methods aims to unify these steps by directly computing trajectories that are both feasible and optimal under
the given criteria.

\subsection{Optimization-Based Motion Planning}
Rather than searching discretely for a path, trajectory optimization treats motion planning as a continuous optimization problem: finding a
time-parametrized state/control sequence that minimizes a cost (such as time or energy) while satisfying system dynamics and constraints.
This approach is rooted in optimal control theory.
Modern optimal control solvers often use direct methods (also known as transcription methods) which discretize the continuous-time problem into a
finite-dimensional problem.
In a direct transcription approach, the time horizon is divided into $N$ intervals, and the state $x_n$ and control input $u_n$ at each time step are
treated as decision variables.
The vehicle's discrete-time dynamics $x_{n+1} = f(x_n, u_n)$ are imposed as constraints linking these variables across time
\cite{tedrake2023trajopt}.
This transforms the trajectory planning task into a large constrained optimization (typically a nonlinear program).
When the system dynamics are linear (or linearized) and constraints and costs are convex (e.g., quadratic cost, linear constraints), the
transcription yields a convex optimization problem – specifically a linear or quadratic program that can be solved efficiently to global optimality
\cite{tedrake2023trajopt}.
In such cases, algorithms can reliably find the optimal trajectory in real time, even online within a model predictive control loop
\cite{tedrake2023trajopt}.

However, for a car-like vehicle, the true dynamics are nonlinear and involve non-convex constraints (especially for obstacle avoidance).
Directly transcribed optimal trajectory planning generally leads to a non-convex problem that standard solvers can only solve to local optimality.
A rich body of work has explored strategies to cope with this non-convexity.
One strategy is to exploit sequential convex optimization: the idea is to iteratively approximate the non-convex problem with a sequence of convex
problems that are easier to solve.
For instance, Schulman et al.
present a trajectory optimizer that at each iteration linearizes or convexifies the collision avoidance constraints and solves a convex sub-problem; by
gradually tightening the approximation, the method converges to a feasible local optimum \cite{schulman_finding_2013}.
Such sequential convex programming approaches (including algorithms like CHOMP and TrajOpt) have demonstrated fast convergence on complex motion
planning tasks, effectively handling high-dimensional robots by solving a series of convex sub-problems.
The key advantage is that each convexified problem can be solved to global optimality, providing a well-defined improvement at each iteration.
The downside is that global optimality of the overall non-convex problem is not guaranteed – the result depends on the quality of the convex
approximations and initial guesses.
Nevertheless, these methods illustrate the central role of convex optimization in modern motion planning: even when the full problem is non-convex,
formulating as much as possible in convex terms (dynamics, cost, safe regions, etc.) leads to more robust and efficient solvers.

Another prominent trajectory optimization framework is Model Predictive Control (MPC) \cite{falcone_predictive_2007,gray_robust_2013}, which can be
seen as a particular implementation of optimal control solved repeatedly in a receding horizon.
In MPC, at each time step a finite-horizon optimal control problem is solved (often by direct transcription as above) to yield an optimal trajectory
and control sequence, of which only the first few control actions are applied before the horizon slides forward.
MPC has been widely adopted in vehicle trajectory planning and tracking due to its ability to handle multi-constraint, multi-variable control
problems in real time.
To ensure tractability, MPC formulations for vehicles often make simplifying assumptions on the vehicle model.
Depending on the scenario, MPC can employ either a kinematic model or a dynamic model, and either use the full nonlinear model or a linearized
version of it \cite{xia_survey_2024}.
Nonlinear MPC (using the full vehicle dynamics) provides higher fidelity and can accurately capture system behavior, but at the cost of significant
computational load \cite{xia_survey_2024}.
For real-time performance, especially in fast update cycles, practitioners commonly use linear time-varying (LTV) MPC or linear time-invariant (LTI)
MPC, where the vehicle model is linearized around a current operating point or along a reference trajectory \cite{xia_survey_2024}.
This yields a convex quadratic program at each MPC step, greatly reducing computation time while still accounting for vehicle constraints (like
acceleration limits, steering limits, etc.)
\cite{xia_survey_2024}.
However, even with linearization, solving constrained optimal control problems in real time remains computationally demanding, especially at high
planning frequencies.
To further enhance efficiency, many trajectory planners adopt simplified motion models that maintain convexity while retaining key dynamic
properties.
One such approach is the use of linear integrator models, which abstract vehicle motion into a set of linear equations, enabling fast convex
optimization.

\subsection{Vehicle Dynamics Modeling in Planning}

\subsubsection{Linear Integrator Models for Convex Optimization}

Linear integrator models (e.g. double or triple integrators for position, velocity, and acceleration) are popular in trajectory planning because they
yield linear dynamics that make the optimization problem convex.
With such models, vehicle dynamics are expressed as simple linear equations (position as a double-integrator of acceleration, etc.).
For instance, modeling motion with a triple integrator (including acceleration as a state and jerk as control) lets one impose acceleration limits as
linear state constraints \cite{esterle_optimal_2020}.
Esterle et al.
leverage this property to encode vehicle non-holonomic behavior (orientation) and collision avoidance with linear constraints,
using a disjunctive (mixed-integer) formulation to approximate the otherwise nonlinear orientation constraints \cite{esterle_optimal_2020}.
By approximating non-holonomy in this way, they maintain a convex formulation (MIQP) for the planner while still respecting vehicle orientation
limits, and show that the resulting trajectories remain feasible when validated with a full nonlinear model \cite{esterle_optimal_2020}.
This demonstrates how integrator-based models can incorporate complex vehicle constraints through clever linear approximations, preserving convexity
of the optimization.

However, a challenge arises when planning on curved roads or general road topologies using simple integrator models.
In a global frame, ensuring the vehicle stays within lane/road boundaries introduces coupling between the vehicle's lateral and longitudinal motion
(e.g. curvature and speed constraints) that is generally nonlinear.
Eilbrecht and Stursberg point out that planning with linear integrator dynamics on a curved road inherently produces non-convex coupled constraints
on states and inputs \cite{eilbrecht_challenges_2020}.
For example, limiting lateral acceleration or enforcing a maximum curvature for a given speed couples the longitudinal velocity and lateral position
in a non-convex way.
This coupling can impede computationally efficient planning \cite{eilbrecht_challenges_2020}.
To address this, they propose modifying such constraints via inner approximations – effectively relaxing or convexifying the road-curvature
constraints \cite{eilbrecht_challenges_2020}.
By computing convex inner approximations of the feasible region (using methods like quantifier elimination), they transform the originally non-convex
road constraints into conservative convex constraints \cite{eilbrecht_challenges_2020}.
The result is that the planner can safely account for road geometry (staying in lane on curved roads) without losing the convex nature of the
problem.
This insight underlines the need for carefully formulated constraints: even with a double-integrator model, one often must introduce additional
constraints (like lateral acceleration limits, curvature bounds, or road boundary conditions) and approximate them in convex form to retain a
tractable optimization problem.

\subsubsection{Kinematic vs.
	Dynamic Bicycle Models and Constraints}

Vehicle models range from simple kinematic bicycles (single-track models without tire
slip dynamics) to more complex dynamic models that include tire forces and slip.
A key trade-off is that kinematic models are simpler and can often be handled in (or approximated to) a convex optimization framework, whereas
dynamic models are more accurate but lead to non-convex formulations that usually require nonlinear or mixed-integer programming.
Kong et al.
compare these two model types and highlight this trade-off \cite{kong_kinematic_2015}.
In their study, a kinematic single-track model (bicycle model) was used in an MPC controller and contrasted with a full dynamic single-track
(tire-force) model.
They found that the kinematic model can achieve similar prediction accuracy as the dynamic model when discretized appropriately, while being
significantly less computationally expensive \cite{kong_kinematic_2015}.
Notably, using a coarse update rate (200 ms) with the kinematic model yielded accuracy comparable to a 100 ms update with the dynamic model
\cite{kong_kinematic_2015}.
At identical update rates, the kinematic model actually predicted vehicle motion more accurately than the dynamic model in their tests
\cite{kong_kinematic_2015}.
This indicates that for many planning scenarios (especially at moderate speeds), a well-tuned kinematic model is sufficient and can be used with a
larger time-step, directly reducing computation load.

Another advantage of the kinematic bicycle model noted by Kong et al.
is its numerical robustness at low speeds.
The dynamic model with tire equations can suffer singularities or poor conditioning as speed approaches zero (e.g. in stop-and-go scenarios), whereas
the kinematic model has no such issue \cite{kong_kinematic_2015}.
This means a planner based on a kinematic model can naturally handle scenarios like stop-and-go traffic or tight maneuvers, which might complicate a
dynamic model-based optimizer.
Indeed, Kong et al.
report that their kinematic-model MPC could handle a wide range of speeds (including zero) with lower computational cost,
while the dynamic model-based controller struggled in very low-speed regimes \cite{kong_kinematic_2015}.
The flip side is that at higher speeds (where significant lateral tire forces and slip arise), the dynamic model outperforms the kinematic model in
accuracy \cite{kong_kinematic_2015}.
In other words, the kinematic model is convex-friendly and adequate for low-to-mid speed planning, but one must impose additional constraints to
ensure it stays within its valid regime; beyond that regime (e.g. high-speed cornering), a dynamic model (which leads to a non-convex problem) would
capture necessary effects like tire slip more accurately \cite{kong_kinematic_2015}.

To reconcile the use of a simpler model with vehicle limits, researchers introduce constraints or adaptive limits into kinematic model planners.
One common approach is to enforce a speed-dependent curvature or steering constraint to mimic the handling limits of the vehicle.
Polack et al.
implement this by limiting the steering angle as a function of forward velocity in their kinematic bicycle MPC planner \cite{polack_guaranteeing_2018}.
This effectively imposes an upper bound on curvature (or lateral acceleration) at high speeds – a direct analog of an "adaptive lateral speed
constraint".
By doing so, they ensure the planned trajectory remains feasible for the real vehicle at all times \cite{polack_guaranteeing_2018}.
In fact, Polack et al.
emphasize that this speed-conditioned steering limit "ensures the validity of the kinematic bicycle model at any time" \cite{polack_guaranteeing_2018}.
In practice, this means the planner will automatically slow down the vehicle (or reduce steering commands) for sharp turns, respecting a friction or
handling limit without needing a full dynamic model.
The steering-angle constraint coupled with speed is a nonlinear coupling (since allowable steering depends on velocity), but it can be handled by
conservative approximation or by embedding it as a lookup constraint in the MPC.
This kind of model-based constraint is an example of a relaxation technique: it keeps the optimization mostly convex (the kinematic model and other
constraints remain linear or convex), by carving out any solutions that would violate the vehicle's true dynamic limits.
Similarly, Polack's two-level architecture \cite{polack_guaranteeing_2018} uses a 10 Hz kinematic-MPC planner with these constraints, then a 100 Hz
low-level controller to track the plan.
This ensured consistency between the planned path and what the dynamic controller could actually follow, effectively guaranteeing that the convex
planner's output was feasible for the real car's dynamics.

In summary, kinematic bicycle models with added constraints combine the best of both worlds: they retain the convex (or easily linearized) structure
of the motion planning problem while capturing essential vehicle limitations.
If a planner uses a pure double-integrator or kinematic model without such constraints, it may generate trajectories that a real vehicle cannot
follow (e.g. demanding too high lateral acceleration on a curve).
The cited works show how to avoid that: by integrating road geometry and vehicle handling constraints (e.g. lateral acceleration, curvature, or
steering limits that depend on speed) into the model, one can maintain a convex optimization formulation that is both computationally efficient and
yields physically feasible trajectories \cite{polack_guaranteeing_2018,eilbrecht_challenges_2020}.

\subsection{Summary}

The reviewed literature highlights the critical trade-offs in motion planning: simplified models enable convex optimization and real-time
feasibility, but additional constraints must be imposed to ensure trajectory feasibility.
Linear integrator models provide a computationally efficient formulation but require convex approximations for road geometry and vehicle constraints.
Kinematic models, when constrained appropriately, offer a balance between efficiency and dynamic feasibility, while dynamic models provide higher
accuracy at a significant computational cost.

Building upon these insights, this thesis develops a motion planning framework that leverages convex formulations of vehicle dynamics and road
topology constraints.
The next section formalizes this problem statement.

